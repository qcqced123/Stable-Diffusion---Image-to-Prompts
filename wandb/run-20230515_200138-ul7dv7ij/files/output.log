
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
[1/3] Train & Validation
/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  torch.nn.utils.clip_grad_norm(                                                                                   | 0/1364 [00:00<?, ?it/s]

















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1364/1364 [2:52:34<00:00,  5.77s/it]
Traceback (most recent call last):                                                                                  | 0/341 [00:00<?, ?it/s]
  File "/home/qcqced/바탕화면/ML_Test/image2text/train.py", line 19, in <module>
    main('image2text_config.json', CFG)
  File "/home/qcqced/바탕화면/ML_Test/image2text/train.py", line 15, in main
    getattr(train_loop, cfg.loop)(cfg)
  File "/home/qcqced/바탕화면/ML_Test/image2text/trainer/train_loop.py", line 37, in train_loop
    valid_metric = train_input.valid_fn(
  File "/home/qcqced/바탕화면/ML_Test/image2text/trainer/trainer.py", line 144, in valid_fn
    image_features = model(clip_images, 'vision', style_features=style_images)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/qcqced/바탕화면/ML_Test/image2text/model/model.py", line 114, in forward
    outputs = self.vision_model(inputs)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/models/clip/modeling_clip.py", line 859, in forward
    hidden_states = self.embeddings(pixel_values)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/models/clip/modeling_clip.py", line 195, in forward
    patch_embeds = self.patch_embedding(pixel_values)  # shape = [*, width, grid, grid]
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [128, 1, 3, 224, 224]