
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                        | 0/16507 [00:00<?, ?it/s]
Traceback (most recent call last):                                                                                           | 0/16507 [00:00<?, ?it/s]
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 248, in __getattr__
    return self.data[item]
KeyError: 'size'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/qcqced/바탕화면/ML_Test/image2text/train.py", line 49, in <module>
    main('image2text_config.json', CFG)
  File "/home/qcqced/바탕화면/ML_Test/image2text/train.py", line 30, in main
    getattr(train_loop, cfg.loop)(cfg)  # init object
  File "/home/qcqced/바탕화면/ML_Test/image2text/trainer/train_loop.py", line 39, in train_loop
    train_loss, grad_norm, lr = train_input.train_fn(
  File "/home/qcqced/바탕화면/ML_Test/image2text/trainer/trainer.py", line 103, in train_fn
    text_features = model(labels, 'text')
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/qcqced/바탕화면/ML_Test/image2text/model/model.py", line 124, in forward
    outputs = self.text_model(inputs)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/models/clip/modeling_clip.py", line 709, in forward
    input_shape = input_ids.size()
  File "/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 250, in __getattr__
    raise AttributeError
AttributeError
torch.Size([16, 1024]) torch.Size([16, 1920])